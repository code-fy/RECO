{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(0, os.path.join(BASE_DIR))\n",
    "\n",
    "from offline import SparkSessionBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成spark Session对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OriginArticleData(SparkSessionBase):\n",
    "    \n",
    "    SPARK_APP_NAME = \"mergeArticle\"\n",
    "    ENABLE_HIVE_SUPPORT = True\n",
    "    SPARK_EXECUTOR_MEMORY = \"4g\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.spark = self._create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa = OriginArticleData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取hive中的文章数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa.spark.sql(\"use fytang\")\n",
    "article_data = oa.spark.sql(\"select * from article_data limit 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将文章进行分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(partition):\n",
    "    import os\n",
    "    import re\n",
    "    import jieba\n",
    "    import jieba.analyse\n",
    "    import jieba.posseg as pseg\n",
    "    import codecs\n",
    "    \n",
    "    abspath = \"/Users/hycao/text\"\n",
    "    \n",
    "    userDict_path = os.path.join(abspath, \"ITKeywords.txt\")\n",
    "    jieba.load_userdict(userDict_path)\n",
    "    stopwords_path = os.path.join(abspath, \"stopwords.txt\")\n",
    "    \n",
    "    def cut_sentence(sentence):\n",
    "        seg_list = pseg.lcut(sentence)\n",
    "        seg_list = [i for i in seg_list if i.flag not in stopwords_path]\n",
    "        filtered_words_list = []\n",
    "        for seg in seg_list:\n",
    "            if len(seg.word) <= 1:\n",
    "                continue\n",
    "            elif seg.flag == \"eng\":\n",
    "                if len(seg.word) <= 2:\n",
    "                    continue\n",
    "                else:\n",
    "                    filtered_words_list.append(seg.word)\n",
    "            elif seg.flag.startswith(\"n\"):\n",
    "                filtered_words_list.append(seg.word)\n",
    "            elif seg.flag in [\"X\", \"eng\"]:\n",
    "                filtered_words_list.append(seg.word)\n",
    "        return filtered_words_list\n",
    "    \n",
    "    for row in partition:\n",
    "        sentence = re.sub(\"<.*?>\", \"\", row.sentence)\n",
    "        words = cut_sentence(sentence)\n",
    "        yield row.article_id, row.channel_id, words\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|article_id|channel_id|               words|\n",
      "+----------+----------+--------------------+\n",
      "|         1|        17|[Vue, props, 用法, ...|\n",
      "|         2|        17|                  []|\n",
      "|         3|        17|[JavaScript, 区别, ...|\n",
      "|         4|        17|[vue2, vuex, elem...|\n",
      "|         5|        17|[immutability, Re...|\n",
      "+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df = article_data.rdd.mapPartitions(segmentation).toDF([\"article_id\", \"channel_id\", \"words\"])\n",
    "words_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"countFeatures\", vocabSize=200*10000, minDF=1.0)\n",
    "cv_model = cv.fit(words_df)\n",
    "cv_model.write().overwrite().save(\"hdfs://localhost:9000/fytang/models/CV.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizerModel\n",
    "cv_model = CountVectorizerModel.load(\"hdfs://localhost:9000/fytang/models/CV.model\")\n",
    "cv_result = cv_model.transform(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "idf = IDF(inputCol = \"countFeatures\", outputCol = \"idfFeature\")\n",
    "idfmodel = idf.fit(cv_result)\n",
    "idfmodel.write().overwrite().save(\"hdfs://localhost:9000/fytang/models/IDF2.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['数据',\n",
       " '组件',\n",
       " 'child',\n",
       " 'let',\n",
       " 'obj',\n",
       " 'div',\n",
       " 'log',\n",
       " 'console',\n",
       " 'props',\n",
       " 'msg',\n",
       " 'forChildMsg',\n",
       " 'obj2',\n",
       " 'for',\n",
       " 'mongodb',\n",
       " 'var',\n",
       " 'ownChildMsg',\n",
       " 'childNode',\n",
       " '数组',\n",
       " 'key',\n",
       " 'immutable',\n",
       " 'data',\n",
       " 'name',\n",
       " 'array',\n",
       " 'template',\n",
       " 'return',\n",
       " '对象',\n",
       " 'update',\n",
       " '项目',\n",
       " 'children',\n",
       " 'JSON',\n",
       " 'arr',\n",
       " 'function',\n",
       " 'value',\n",
       " '用法',\n",
       " 'the',\n",
       " '方法',\n",
       " 'mongod',\n",
       " '首席',\n",
       " '苏南',\n",
       " '原始数据',\n",
       " 'Object',\n",
       " 'set',\n",
       " 'Vue',\n",
       " 'data2',\n",
       " 'rentNode',\n",
       " 'object',\n",
       " '拷贝',\n",
       " 'Array',\n",
       " '文章',\n",
       " '定义',\n",
       " '系统',\n",
       " 'rent',\n",
       " '文件夹',\n",
       " 'String',\n",
       " '数据库',\n",
       " 'remove',\n",
       " 'prop',\n",
       " '字符串',\n",
       " 'class',\n",
       " 'stringify',\n",
       " 'apply',\n",
       " 'rawObj',\n",
       " 'bin',\n",
       " 'components',\n",
       " '总结',\n",
       " 'add',\n",
       " 'vue2',\n",
       " 'splice',\n",
       " 'amp',\n",
       " '属性',\n",
       " '函数',\n",
       " 'tougu',\n",
       " 'Number',\n",
       " 'element',\n",
       " 'this',\n",
       " 'rse',\n",
       " 'API',\n",
       " 'merge',\n",
       " 'model',\n",
       " 'input',\n",
       " '方式',\n",
       " 'val',\n",
       " '命令',\n",
       " 'address',\n",
       " 'deepclone',\n",
       " '模板',\n",
       " '类型',\n",
       " 'unset',\n",
       " 'windows',\n",
       " 'ssign',\n",
       " '警告',\n",
       " 'unshift',\n",
       " 'original',\n",
       " 'type',\n",
       " 'ShenZhen',\n",
       " 'Map',\n",
       " 'hobby',\n",
       " 'nodejs',\n",
       " 'new',\n",
       " 'validator',\n",
       " 'copyObj',\n",
       " 'from',\n",
       " '传递数据',\n",
       " 'Set',\n",
       " 'defa',\n",
       " 'JavaScript',\n",
       " 'cmd',\n",
       " '平头',\n",
       " 'Helpers',\n",
       " 'objClone',\n",
       " '时候',\n",
       " '静态',\n",
       " 'touzi',\n",
       " 'push',\n",
       " 'isArray',\n",
       " 'Immutability',\n",
       " 'node',\n",
       " '选项',\n",
       " '问题',\n",
       " '官方',\n",
       " 'get',\n",
       " 'List',\n",
       " 'const',\n",
       " 'list',\n",
       " '大家',\n",
       " '文件',\n",
       " 'example',\n",
       " '快捷键',\n",
       " '兴趣',\n",
       " 'ES6',\n",
       " '声明',\n",
       " 'use',\n",
       " 'moneyIncomePay',\n",
       " 'txt',\n",
       " '地址',\n",
       " '动态',\n",
       " 'list3',\n",
       " 'obj3',\n",
       " 'outdb',\n",
       " 'objB',\n",
       " 'propE',\n",
       " '有点',\n",
       " '示例',\n",
       " 'trinoc',\n",
       " '层级',\n",
       " 'childMsg2',\n",
       " 'customClone',\n",
       " 'items',\n",
       " 'express',\n",
       " '嵌套',\n",
       " 'array2',\n",
       " 'getIn',\n",
       " 'objA',\n",
       " '父子',\n",
       " 'childMsg1',\n",
       " '列表',\n",
       " 'toggle',\n",
       " '资金',\n",
       " 'immutability',\n",
       " 'proportion',\n",
       " '空间',\n",
       " 'robomongod',\n",
       " '功能',\n",
       " '交流',\n",
       " 'and',\n",
       " '原因',\n",
       " '驼峰',\n",
       " '链接',\n",
       " '输入框',\n",
       " 'copy',\n",
       " '服务端',\n",
       " 'call',\n",
       " 'events',\n",
       " '形式',\n",
       " '全栈',\n",
       " 'cloneObj',\n",
       " 'arg',\n",
       " '思维能力',\n",
       " '信息',\n",
       " '宝宝',\n",
       " '代码',\n",
       " '服务器',\n",
       " '特性',\n",
       " 'component',\n",
       " 'boolean',\n",
       " '都行',\n",
       " '程序',\n",
       " '路径',\n",
       " 'target',\n",
       " 'window',\n",
       " 'list2',\n",
       " '谢谢',\n",
       " '人员',\n",
       " '和子',\n",
       " '原创',\n",
       " '错误',\n",
       " '内容',\n",
       " 'test',\n",
       " '环境',\n",
       " 'https',\n",
       " '时间',\n",
       " 'exe',\n",
       " 'github',\n",
       " '指向',\n",
       " '技术',\n",
       " 'localhost',\n",
       " '和尚',\n",
       " 'Function',\n",
       " 'run',\n",
       " 'true',\n",
       " 'mongoimport',\n",
       " 'else',\n",
       " '重命名',\n",
       " 'toString',\n",
       " '同学',\n",
       " '基本',\n",
       " '无法',\n",
       " '表格',\n",
       " '命名',\n",
       " '原生',\n",
       " 'Star',\n",
       " 'start',\n",
       " 'list1',\n",
       " '博客',\n",
       " 'data1',\n",
       " 'index',\n",
       " '作者',\n",
       " 'admin',\n",
       " '选择器',\n",
       " 'computed',\n",
       " '数据类型',\n",
       " '区别',\n",
       " '出镜',\n",
       " 'string',\n",
       " 'false',\n",
       " 'Dynamic',\n",
       " '瓶颈',\n",
       " 'prototype',\n",
       " '过程',\n",
       " 'helper',\n",
       " 'job',\n",
       " '向子',\n",
       " '基础',\n",
       " '字段',\n",
       " 'Boolean',\n",
       " '意思',\n",
       " '规格',\n",
       " '情况',\n",
       " 'extend',\n",
       " '单向',\n",
       " '版本',\n",
       " 'vuex',\n",
       " 'npm',\n",
       " 'honeyBadger8',\n",
       " 'typeof',\n",
       " '名字',\n",
       " 'watch',\n",
       " '内存空间',\n",
       " '布尔值',\n",
       " 'upsert',\n",
       " 'renders',\n",
       " '标签',\n",
       " '书写',\n",
       " '学校',\n",
       " 'level',\n",
       " 'isValid',\n",
       " '人群',\n",
       " '端口',\n",
       " '步骤',\n",
       " '好气',\n",
       " 'toggles',\n",
       " '数据流',\n",
       " 'pure',\n",
       " '屏幕',\n",
       " 'less',\n",
       " 'functional',\n",
       " 'toJS',\n",
       " 'fields',\n",
       " '著作权',\n",
       " 'strings',\n",
       " '建议',\n",
       " 'Html',\n",
       " 'robo3t',\n",
       " '效果',\n",
       " '内存',\n",
       " 'map',\n",
       " 'lends',\n",
       " 'much',\n",
       " '实例',\n",
       " 'SymbolVue',\n",
       " 'end',\n",
       " 'file',\n",
       " '密码',\n",
       " 'size',\n",
       " '身份',\n",
       " '泥马',\n",
       " 'router',\n",
       " '新旧',\n",
       " '全部',\n",
       " '文本',\n",
       " 'property',\n",
       " 'fromJS',\n",
       " '可视化',\n",
       " 'Ian',\n",
       " '饮用',\n",
       " '宝剑锋',\n",
       " '后台',\n",
       " '贵在',\n",
       " '用户',\n",
       " '个人信息',\n",
       " '三观',\n",
       " '解决方案',\n",
       " '文档',\n",
       " '主机名',\n",
       " 'details',\n",
       " 'height',\n",
       " 'React',\n",
       " '传导',\n",
       " 'signature',\n",
       " '可维护性',\n",
       " 'Immutable',\n",
       " 'Mongo',\n",
       " '端口号',\n",
       " '局部',\n",
       " '大神',\n",
       " 'origin',\n",
       " 'encourages',\n",
       " '信息管理',\n",
       " 'robomongo',\n",
       " 'com',\n",
       " '下文',\n",
       " '文件名',\n",
       " 'concat',\n",
       " 'development',\n",
       " 'ck2',\n",
       " 'mongodb4',\n",
       " 'mutating',\n",
       " '盘符',\n",
       " 'functions',\n",
       " '例子',\n",
       " '性能',\n",
       " 'mongo',\n",
       " 'About',\n",
       " '味道',\n",
       " 'formJS',\n",
       " '宠幸',\n",
       " 'react',\n",
       " 'bind',\n",
       " '流水',\n",
       " 'Mutate',\n",
       " '小娜',\n",
       " '内存地址',\n",
       " 'JQuery',\n",
       " 'will',\n",
       " '局部变量',\n",
       " '时代',\n",
       " '个性',\n",
       " 'whenever',\n",
       " '视图',\n",
       " 'connection',\n",
       " 'aaa',\n",
       " 'out',\n",
       " '旧值',\n",
       " '参数',\n",
       " '日志',\n",
       " '状态',\n",
       " '小结',\n",
       " 'keys',\n",
       " '凡事',\n",
       " '宝贵意见',\n",
       " 'updates',\n",
       " '长度',\n",
       " 'enabling',\n",
       " 'rray',\n",
       " 'overwritten',\n",
       " '上线',\n",
       " 'source',\n",
       " '作用域',\n",
       " 'current',\n",
       " '办法',\n",
       " '浏览器',\n",
       " 'es6',\n",
       " '规定',\n",
       " 'propF',\n",
       " 'str',\n",
       " '思想',\n",
       " 'being',\n",
       " '前序',\n",
       " '条条框框',\n",
       " 'application',\n",
       " 'techniques',\n",
       " 'Avoid',\n",
       " 'propD',\n",
       " 'lazy',\n",
       " 'assign',\n",
       " '万幸',\n",
       " '执行命令',\n",
       " '命令提示符',\n",
       " 'evaluation',\n",
       " 'sses',\n",
       " 'propC',\n",
       " '套路',\n",
       " 'gitHub',\n",
       " 'weixin',\n",
       " '结果',\n",
       " 'blog',\n",
       " '编辑',\n",
       " '副本',\n",
       " '高阶',\n",
       " '多种类型',\n",
       " '种类',\n",
       " '上例',\n",
       " '张小龙',\n",
       " 'without',\n",
       " '生效',\n",
       " 'returned',\n",
       " 'propA',\n",
       " '树形',\n",
       " '出场',\n",
       " '标的',\n",
       " 'Prop',\n",
       " '潮流',\n",
       " 'number',\n",
       " 'organization',\n",
       " 'asOwnProperty',\n",
       " '个人观点',\n",
       " '画面',\n",
       " 'admincd',\n",
       " '技巧',\n",
       " 'follow',\n",
       " 'age',\n",
       " 'api',\n",
       " 'mutated',\n",
       " '新建',\n",
       " '场景',\n",
       " '单据',\n",
       " '时会',\n",
       " '按钮',\n",
       " 'csdn',\n",
       " '共享内存',\n",
       " 'git',\n",
       " '明白',\n",
       " '工具',\n",
       " 'article',\n",
       " '联系',\n",
       " 'ECMAScript',\n",
       " 'http',\n",
       " 'Issues',\n",
       " '安全性',\n",
       " '缘份',\n",
       " 'root',\n",
       " 'msc',\n",
       " '差点',\n",
       " '商业',\n",
       " '解析器',\n",
       " '目录',\n",
       " '梅花香',\n",
       " '对方',\n",
       " 'shallow',\n",
       " '大佬',\n",
       " '用户名',\n",
       " '句号',\n",
       " 'warn',\n",
       " '关系',\n",
       " 'propB',\n",
       " 'since',\n",
       " 'clone',\n",
       " 'undefined',\n",
       " '时尚',\n",
       " '主题',\n",
       " 'jQuery',\n",
       " 'javascript',\n",
       " 'deep',\n",
       " 'down',\n",
       " '指针',\n",
       " 'installnpm',\n",
       " '金融',\n",
       " 'length',\n",
       " '区域',\n",
       " '温度',\n",
       " '余地',\n",
       " 'bat',\n",
       " 'mergeIn',\n",
       " 'invoked',\n",
       " 'reverse',\n",
       " '面试官',\n",
       " '普通',\n",
       " 'directly',\n",
       " '结缘',\n",
       " '程序员',\n",
       " 'dev',\n",
       " '开源',\n",
       " '我会',\n",
       " 'install',\n",
       " 'vue',\n",
       " 'demo',\n",
       " 'services',\n",
       " 'city',\n",
       " 'simpler',\n",
       " 'Instead',\n",
       " '工厂',\n",
       " 'other',\n",
       " 'E盘',\n",
       " '省份',\n",
       " '商量',\n",
       " 'ECMA',\n",
       " 'such',\n",
       " '数字',\n",
       " 'required',\n",
       " '结尾',\n",
       " 'bbb',\n",
       " 'programming',\n",
       " 'itself',\n",
       " '管理员',\n",
       " '收支',\n",
       " '地方',\n",
       " 'wdlhao',\n",
       " '右键',\n",
       " 'message',\n",
       " '语法',\n",
       " 'net',\n",
       " 'sex',\n",
       " '数据表',\n",
       " 'with',\n",
       " 'based',\n",
       " 'server',\n",
       " 'web',\n",
       " '由子',\n",
       " 'changing']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40546511, 1.09861229, 1.09861229, 0.40546511, 0.69314718,\n",
       "       1.09861229, 0.18232156, 0.40546511, 1.09861229, 1.09861229,\n",
       "       1.09861229, 1.09861229, 0.40546511, 1.09861229, 0.40546511,\n",
       "       1.09861229, 1.09861229, 0.69314718, 0.69314718, 1.09861229])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfmodel.idf.toArray()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizerModel\n",
    "cv_model = CountVectorizerModel.load(\"hdfs://localhost:9000/fytang/models/CV.model\")\n",
    "from pyspark.ml.feature import IDFModel\n",
    "idf_model = IDFModel.load(\"hdfs://localhost:9000/fytang/models/IDF2.model\")\n",
    "cv_result = cv_model.transform(words_df)\n",
    "tfidf_result = idf_model.transform(cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+--------------------+\n",
      "|article_id|channel_id|               words|       countFeatures|          idfFeature|\n",
      "+----------+----------+--------------------+--------------------+--------------------+\n",
      "|         1|        17|[Vue, props, 用法, ...|(529,[0,1,2,3,5,6...|(529,[0,1,2,3,5,6...|\n",
      "|         2|        17|                  []|         (529,[],[])|         (529,[],[])|\n",
      "|         3|        17|[JavaScript, 区别, ...|(529,[3,4,6,7,12,...|(529,[3,4,6,7,12,...|\n",
      "|         4|        17|[vue2, vuex, elem...|(529,[0,6,13,27,3...|(529,[0,6,13,27,3...|\n",
      "|         5|        17|[immutability, Re...|(529,[0,3,4,6,7,1...|(529,[0,3,4,6,7,1...|\n",
      "+----------+----------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+-------+\n",
      "|article_id|channel_id|index|  tfidf|\n",
      "+----------+----------+-----+-------+\n",
      "|         1|        17|    1|60.4237|\n",
      "|         1|        17|    2|49.4376|\n",
      "|         1|        17|    5|43.9445|\n",
      "|         1|        17|    8| 34.057|\n",
      "|         1|        17|    9|26.3667|\n",
      "|         1|        17|   10|25.2681|\n",
      "|         1|        17|   15| 19.775|\n",
      "|         1|        17|   16| 19.775|\n",
      "|         1|        17|   23|17.5778|\n",
      "|         1|        17|    0|10.1366|\n",
      "|         1|        17|   42| 9.8875|\n",
      "|         1|        17|   44| 9.8875|\n",
      "|         1|        17|   51| 8.7889|\n",
      "|         1|        17|   53| 8.7889|\n",
      "|         1|        17|   56| 8.7889|\n",
      "|         1|        17|   58| 7.6903|\n",
      "|         1|        17|   12| 7.2984|\n",
      "|         1|        17|   63| 6.5917|\n",
      "|         1|        17|   69| 6.5917|\n",
      "|         1|        17|   78| 5.4931|\n",
      "+----------+----------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def func(partition):\n",
    "    TOPK = 20\n",
    "    for row in partition:\n",
    "        _ = list(zip(row.idfFeature.indices, row.idfFeature.values))\n",
    "        _ = sorted(_, key=lambda x : x[1], reverse=True)\n",
    "        result = _[:TOPK]\n",
    "        for words_index, tfidf in result:\n",
    "            yield row.article_id, row.channel_id, int(words_index), round(float(tfidf), 4)\n",
    "tfidf_index_values = tfidf_result.rdd.mapPartitions(func).toDF([\"article_id\", \"channel_id\", \"index\", \"tfidf\"])\n",
    "tfidf_index_values.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank(partition):\n",
    "    import os\n",
    "    import jieba\n",
    "    import jieba.analyse\n",
    "    import jieba.posseg as pseg\n",
    "    import codecs\n",
    "    \n",
    "    abspath = \"/Users/hycao/text\"\n",
    "    userDict_path = os.path.join(abspath, \"ITKeywords.txt\")\n",
    "    jieba.load_userdict(userDict_path)\n",
    "    stopwords_path = os.path.join(abspath, \"stopwords.txt\")\n",
    "    \n",
    "    def get_stopwords_list():\n",
    "        stopwords_list = [i.strip()\n",
    "                           for i in codecs.open(stopwords_path).readlines()\n",
    "                         ]\n",
    "        return stopwords_list\n",
    "    \n",
    "    stopwords_list = get_stopwords_list()\n",
    "    \n",
    "    class TextRank(jieba.analyse.TextRank):\n",
    "        def __init__(self, windows=20, word_min_len=2):\n",
    "            super(TextRank, self).__init__()\n",
    "            self.span = windows\n",
    "            self.word_min_len = word_min_len\n",
    "            self.pos_filt = frozenset(('n', 'x', 'eng', 'f', 's', 't', 'nr', 'ns', 'nt', 'nw', 'nz', 'PER', 'LOC', \"ORG\"))\n",
    "            \n",
    "        def pairfilter(self, wp):\n",
    "            if wp.flag == \"eng\":\n",
    "                if len(wp.word) <= 2:\n",
    "                    return False\n",
    "                if wp.flag in self.pos_filt and len(wp.word.strip()) >= self.word_min_len and wp.word.lower() not in stopwords_list:\n",
    "                    return True\n",
    "        \n",
    "    textrank_model = TextRank(windows=5, word_min_len=2\n",
    "                             )\n",
    "    allwPOS = ('n', 'x', 'eng', 'nr', 'ns', 'nt', 'nw', 'nz', 'c')\n",
    "    for row in partition:\n",
    "        tags = textrank_model.textrank(row.sentence, topK=20, withWeight=True, allowPOS =allwPOS , withFlag=False)\n",
    "        for tag in tags:\n",
    "            yield row.article_id, row.channel_id, tag[0], tag[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "textrank_keywords_df = article_data.rdd.mapPartitions(textrank).toDF([\"article_id\", \"channel_id\", \"keyword\", \"textrank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+-------------------+\n",
      "|article_id|channel_id|    keyword|           textrank|\n",
      "+----------+----------+-----------+-------------------+\n",
      "|         1|        17|        msg|                1.0|\n",
      "|         1|        17|       code| 0.6678609841743154|\n",
      "|         1|        17|      child| 0.6665863972022452|\n",
      "|         1|        17|      props|  0.390571729326677|\n",
      "|         1|        17|     String| 0.3571663376160206|\n",
      "|         1|        17|        pre|  0.347249917686024|\n",
      "|         1|        17|      model| 0.3112348130693862|\n",
      "|         1|        17|       defa| 0.2878898408898146|\n",
      "|         1|        17|     Number| 0.2862310465838811|\n",
      "|         1|        17|forChildMsg|   0.28233337644711|\n",
      "|         1|        17|     return|0.27961147459830155|\n",
      "|         1|        17|      class|0.27464130361555694|\n",
      "|         1|        17|  childNode| 0.2725460378336616|\n",
      "|         1|        17|   computed| 0.2385683350414798|\n",
      "|         1|        17|     strong|0.23129374583079185|\n",
      "|         1|        17|     Object|0.22528891947276747|\n",
      "|         1|        17|   function|0.22451439394776143|\n",
      "|         1|        17|       prop|0.22301179021778744|\n",
      "|         1|        17|       data|0.22092386865223113|\n",
      "|         1|        17|        log| 0.2115359482920021|\n",
      "+----------+----------+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textrank_keywords_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+-------------------+---------+------------------+------+\n",
      "|article_id|channel_id|  keyword|           textrank| keyword1|               idf| index|\n",
      "+----------+----------+---------+-------------------+---------+------------------+------+\n",
      "|         1|        17|childNode| 0.2725460378336616|childNode| 7.869848788205214| 20134|\n",
      "|         3|        17|      amp|0.29969222129374834|      amp|1.5313880611157102|    18|\n",
      "|         3|        17|      jpg| 0.5269060219822252|      jpg| 3.486643603011888|   727|\n",
      "|         4|        17|      jpg|                1.0|      jpg| 3.486643603011888|   727|\n",
      "|         1|        17|   Number| 0.2862310465838811|   Number|3.9439600931418446|  1060|\n",
      "|         4|        17|  element| 0.5477235243943445|  element|3.5778397599698883|   494|\n",
      "|         1|        17| computed| 0.2385683350414798| computed| 5.091381154265656|  2754|\n",
      "|         4|        17|    touzi|0.44956362539337796|    touzi|11.146993521197391|348908|\n",
      "|         5|        17|   upload| 0.2204636367263416|   upload| 4.733534564030034|  1851|\n",
      "|         1|        17|     code| 0.6678609841743154|     code|2.7220252738236703|   270|\n",
      "|         3|        17|     code|0.35360682673950117|     code|2.7220252738236703|   270|\n",
      "|         5|        17|     code|                1.0|     code|2.7220252738236703|   270|\n",
      "|         5|        17|   helper|0.12599454879273628|   helper| 5.461714518105749|  3245|\n",
      "|         1|        17|      log| 0.2115359482920021|      log|2.0027395343490673|    39|\n",
      "|         4|        17|      log|0.30824571727323424|      log|2.0027395343490673|    39|\n",
      "|         5|        17|      log|0.22366778085419262|      log|2.0027395343490673|    39|\n",
      "|         4|        17|      msc| 0.3820562850880666|      msc| 7.681257618397664| 32302|\n",
      "|         5|        17|     auto|0.19297631149738118|     auto|3.2996216850376014|   637|\n",
      "|         1|        17|     defa| 0.2878898408898146|     defa| 2.257823065833978|   179|\n",
      "|         4|        17|    title| 0.4180355726563764|    title|2.5847313664135747|   160|\n",
      "+----------+----------+---------+-------------------+---------+------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf_keywords_values = oa.spark.sql(\"select * from idf_keywords_values\")\n",
    "idf_keywords_values = idf_keywords_values.withColumnRenamed('keyword', 'keyword1')\n",
    "keywords_weights = textrank_keywords_df.join(idf_keywords_values, textrank_keywords_df.keyword == idf_keywords_values.keyword1)\n",
    "keywords_weights.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+-------------------+\n",
      "|article_id|channel_id|  keyword|            weights|\n",
      "+----------+----------+---------+-------------------+\n",
      "|         1|        17|childNode| 2.1448961055753744|\n",
      "|         3|        17|      amp| 0.4589450896984936|\n",
      "|         3|        17|      jpg| 1.8371335109327669|\n",
      "|         4|        17|      jpg|  3.486643603011888|\n",
      "|         1|        17|   Number| 1.1288838251450513|\n",
      "|         4|        17|  element| 1.9596670030489227|\n",
      "|         1|        17| computed| 1.2146423250347254|\n",
      "|         4|        17|    touzi|  5.011282819625995|\n",
      "|         5|        17|   upload|  1.043572244555899|\n",
      "|         1|        17|     code| 1.8179344783232367|\n",
      "|         3|        17|     code| 0.9625267193815098|\n",
      "|         5|        17|     code| 2.7220252738236703|\n",
      "|         5|        17|   helper| 0.6881462563434709|\n",
      "|         1|        17|      log| 0.4236514065804126|\n",
      "|         4|        17|      log| 0.6173358842768913|\n",
      "|         5|        17|      log|0.44794830727681495|\n",
      "|         4|        17|      msc| 2.9346727504894217|\n",
      "|         5|        17|     auto| 0.6367488221153299|\n",
      "|         1|        17|     defa| 0.6500043231802973|\n",
      "|         4|        17|    title|  1.080509656921597|\n",
      "+----------+----------+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keywords_weights = keywords_weights.withColumn('weights', keywords_weights.textrank * keywords_weights.idf).select([\"article_id\",\"channel_id\",\"keyword\",\"weights\"])\n",
    "keywords_weights.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_weights.registerTempTable(\"kw\")\n",
    "keywords_list = oa.spark.sql(\"select article_id, max(channel_id) channel_id, collect_list(keyword) keyword, collect_list(weights) weights from kw group by article_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+\n",
      "|article_id|channel_id|             keyword|             weights|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "|         5|        17|[upload, code, he...|[1.04357224455589...|\n",
      "|         1|        17|[childNode, Numbe...|[2.14489610557537...|\n",
      "|         3|        17|[amp, jpg, code, ...|[0.45894508969849...|\n",
      "|         4|        17|[jpg, element, to...|[3.48664360301188...|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keywords_list.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|article_id|channel_id|            keywords|\n",
      "+----------+----------+--------------------+\n",
      "|         5|        17|Map(pre -> 0.6960...|\n",
      "|         1|        17|Map(pre -> 1.2732...|\n",
      "|         3|        17|Map(number -> 0.9...|\n",
      "|         4|        17|Map(msc -> 2.9346...|\n",
      "+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _func(row):\n",
    "    return row.article_id, row.channel_id, dict(zip(row.keyword,row.weights))\n",
    "keywords_info = keywords_list.rdd.map(_func).toDF(['article_id', 'channel_id', 'keywords'])\n",
    "keywords_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info = oa.spark.sql(\"select t.article_id as article_id2, collect_list(t.keyword) topic from tfidf_keywords_values t inner join textrank_keywords_values r where t.keyword = r.keyword group by article_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|article_id2|               topic|\n",
      "+-----------+--------------------+\n",
      "|        471|             [title]|\n",
      "|        496|            [Object]|\n",
      "|       2659|          [jpg, jpg]|\n",
      "|       2866|      [class, class]|\n",
      "|       3794|          [function]|\n",
      "|       4935|        [data, data]|\n",
      "|       5518|            [Object]|\n",
      "|       5803|[Object, function...|\n",
      "|       7754|               [bin]|\n",
      "|       7833|  [language, String]|\n",
      "|       7982|            [String]|\n",
      "|       8389|    [Object, String]|\n",
      "|       9376|     [amp, key, key]|\n",
      "|       9852|[log, log, log, c...|\n",
      "|      10206|        [data, data]|\n",
      "|      10362|[log, log, log, f...|\n",
      "|      11141|      [class, class]|\n",
      "|      12046|[log, log, log, c...|\n",
      "|      13289|        [data, data]|\n",
      "|      13623|            [String]|\n",
      "+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
